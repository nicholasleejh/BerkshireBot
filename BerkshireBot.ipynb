{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-Powered \"Warren Buffett\" Investment Advisor RAG System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many investors admire Warren Buffett’s investment philosophy but lack the expertise to analyze stocks the way he does. This AI-powered RAG system retrieves historical Buffett investment decisions, Berkshire Hathaway shareholder letters, and company financials to provide Buffett-style insights on modern stocks. This allows us to more closely emulate and learn Buffett's signature \"value investment\" style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "import spacy\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pickle\n",
    "import numpy as np\n",
    "import faiss\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Source: https://www.berkshirehathaway.com/letters/letters.html\n",
    "\n",
    "One setback is that the shareholder's letters are all in PDF format, not markdown, making the text poorly structured. Some pre-defined rules have been created to clean the text, however it is not perfect. Additionally, tables could not be read and extracted properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean text test: This is the first section  cashflow Is Important but Berkshire Hathaway's strategy Is Unique.   Next page starts here.\n"
     ]
    }
   ],
   "source": [
    "def extract_text_and_tables(pdf_path):\n",
    "    full_text = \"\"\n",
    "    tables_data = []\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            # Extract text\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                full_text += page_text + \"\\n\\n\"\n",
    "            # Extract tables (doesn't actually work as tables are not well formatted)\n",
    "            tables = page.extract_tables()\n",
    "            for table in tables:\n",
    "                if table:\n",
    "                    tables_data.append(table)\n",
    "\n",
    "    return full_text, tables_data\n",
    "\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    # Initialize list to store cleaned lines\n",
    "    cleaned_lines = []\n",
    "    # Split text into lines\n",
    "    lines = text.split(\"\\n\")\n",
    "\n",
    "    # Iterate over lines\n",
    "    for line in lines:\n",
    "        # Remove page numbers (if the line is just a number)\n",
    "        if re.fullmatch(r\"\\d+\", line):  \n",
    "            continue  \n",
    "        # Replace page breaks (\\f often represents a new page in PDFs)\n",
    "        line = line.replace(\"\\f\", \" \")\n",
    "        # Remove section dividers (e.g., ***********)\n",
    "        line = re.sub(r'\\*{5,}', ' ', line)\n",
    "        # Remove long sequences of dots (e.g., ...................................)\n",
    "        line = re.sub(r'\\.{5,}', ' ', line)\n",
    "        # Append cleaned line if not empty\n",
    "        if line:\n",
    "            cleaned_lines.append(line)\n",
    "    \n",
    "    # Join lines, ensuring sentences are reconstructed properly\n",
    "    cleaned_text = \" \".join(cleaned_lines)\n",
    "    # Fix spaces before punctuation (caused by broken lines)\n",
    "    cleaned_text = re.sub(r'\\s+([.,!?;])', r'\\1', cleaned_text)\n",
    "    # Fix missing spaces in camelCase-like words\n",
    "    cleaned_text = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', cleaned_text)\n",
    "    # Trim whitespace\n",
    "    cleaned_text = cleaned_text.strip()\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "# Test the function\n",
    "print(\"Clean text test:\", clean_text(\n",
    "\"\"\"\n",
    "************\n",
    "This is the first section..........................................................................\n",
    "12\n",
    "cashflowIsImportant butBerkshireHathaway's strategyIsUnique.\n",
    "\\f\n",
    "Next page starts here.\n",
    "\"\"\"))\n",
    "\n",
    "# Preprocess all shareholder letters\n",
    "for i in range(1977, 2025):\n",
    "    print(f\"Processing {i}...\")\n",
    "    text, tables = extract_text_and_tables(f\"./data/BRK.A Chairman Letters/Chairman's Letter - {i}.pdf\")\n",
    "    processed_text = clean_text(text)\n",
    "    with open(f\"./data/BRK.A Chairman Letters/Chairman's Letter - {i}.txt\", \"w\", encoding='utf-8') as f:\n",
    "        f.write(processed_text)\n",
    "\n",
    "shareholder_text = {}\n",
    "for i in range(1977, 2025):\n",
    "    with open(f\"./data/BRK.A Chairman Letters/Chairman's Letter - {i}.txt\", \"r\", encoding='utf-8') as f:\n",
    "        shareholder_text[i] = f.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunking is done at a sentence level with sliding window using spaCy. 15 sentences form 1 chunk with an overlap of 5 sentences ensuring that each chunk has a reasonable amount of context from the previous chunk, without being excessively redundant.\n",
    "\n",
    "Ideally, chunking would be done on a section or paragraph level. However,\n",
    "1. The format of the letter changes over time and the section headers may not be consistent. E.g., 1977 - \"Insurance Investments\", 1981 - \"General Acquisition Behavior\"\n",
    "2. Due to the PDF format of the letters, pdfplumber is unable to detect paragraph breaks.\n",
    "\n",
    "Metadata for the year is also added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'BERKSHIRE HATHAWAY INC. To the Stockholders of Berkshire Hathaway Inc.: Operating earnings in 1977 of $21,904,000, or $22.54 per share, were moderately better than anticipated a year ago. Of these earnings, $1.43 per share resulted from substantial realized capital gains by Blue Chip Stamps which, to the extent of our proportional interest in that company, are included in our operating earnings figure. Capital gains or losses realized directly by Berkshire Hathaway Inc. or its insurance subsidiaries are not included in our calculation of operating earnings. While too much attention should not be paid to the figure for any single year, over the longer term the record regarding aggregate capital gains or losses obviously is of significance. Textile operations came in well below forecast, while the results of the Illinois National Bank as well as the operating earnings attributable to our equity interest in Blue Chip Stamps were about as anticipated. However, insurance operations, led again by the truly outstanding results of Phil Liesche’s managerial group at National Indemnity Company, were even better than our optimistic expectations. Most companies define “record” earnings as a new high in earnings per share. Since businesses customarily add from year to year to their equity base, we find nothing particularly noteworthy in a management performance combining, say, a 10% increase in equity capital and a 5% increase in earnings per share. After all, even a totally dormant savings account will produce steadily rising interest earnings each year because of compounding. Except for special cases (for example, companies with unusual debt-equity ratios or those with important assets carried at unrealistic balance sheet values), we believe a more appropriate measure of managerial economic performance to be return on equity capital. In 1977 our operating earnings on beginning equity capital amounted to 19%, slightly better than last year and above both our own long-term average and that of American industry in aggregate. But, while our operating earnings per share were up 37% from the year before, our beginning capital was up 24%, making the gain in earnings per share considerably less impressive than it might appear at first glance. We expect difficulty in matching our 1977 rate of return during the forthcoming year.',\n",
       "  'year': 1977},\n",
       " {'text': 'After all, even a totally dormant savings account will produce steadily rising interest earnings each year because of compounding. Except for special cases (for example, companies with unusual debt-equity ratios or those with important assets carried at unrealistic balance sheet values), we believe a more appropriate measure of managerial economic performance to be return on equity capital. In 1977 our operating earnings on beginning equity capital amounted to 19%, slightly better than last year and above both our own long-term average and that of American industry in aggregate. But, while our operating earnings per share were up 37% from the year before, our beginning capital was up 24%, making the gain in earnings per share considerably less impressive than it might appear at first glance. We expect difficulty in matching our 1977 rate of return during the forthcoming year. Beginning equity capital is up 23% from a year ago, and we expect the trend of insurance underwriting profit margins to turn down well before the end of the year. Nevertheless, we expect a reasonably good year and our present estimate, subject to the usual caveats regarding the frailties of forecasts, is that operating earnings will improve somewhat on a per share basis during 1978. Textile Operations The textile business again had a very poor year in 1977. We have mistakenly predicted better results in each of the last two years. This may say something about our forecasting abilities, the nature of the textile industry, or both. Despite strenuous efforts, problems in marketing and manufacturing have persisted. Many difficulties experienced in the marketing area are due primarily to industry conditions, but some of the problems have been of our own making. A few shareholders have questioned the wisdom of remaining in the textile business which, over the longer term, is unlikely to produce returns on capital comparable to those available in many other businesses. Our reasons are several: (1) Our mills in both New Bedford and Manchester are among the largest employers in each town, utilizing a labor force of high average age possessing relatively non-transferable skills.',\n",
       "  'year': 1977},\n",
       " {'text': 'This may say something about our forecasting abilities, the nature of the textile industry, or both. Despite strenuous efforts, problems in marketing and manufacturing have persisted. Many difficulties experienced in the marketing area are due primarily to industry conditions, but some of the problems have been of our own making. A few shareholders have questioned the wisdom of remaining in the textile business which, over the longer term, is unlikely to produce returns on capital comparable to those available in many other businesses. Our reasons are several: (1) Our mills in both New Bedford and Manchester are among the largest employers in each town, utilizing a labor force of high average age possessing relatively non-transferable skills. Our workers and unions have exhibited unusual understanding and effort in cooperating with management to achieve a cost structure and product mix which might allow us to maintain a viable operation. (2) Management also has been energetic and straightforward in its approach to our textile problems. In particular, Ken Chace’s efforts after the change in corporate control took place in 1965 generated capital from the textile division needed to finance the acquisition and expansion of our profitable insurance operation. (3) With hard work and some imagination regarding manufacturing and marketing configurations, it seems reasonable that at least modest profits in the textile division can be achieved in the future. Insurance Underwriting Our insurance operation continued to grow significantly in 1977. It was early in 1967 that we made our entry into this industry through the purchase of National Indemnity Company and National Fire and Marine Insurance Company (sister companies) for approximately $8.6 million. In that year their premium volume amounted to $22 million. In 1977 our aggregate insurance premium volume was $151 million. No additional shares of Berkshire Hathaway stock have been issued to achieve any of this growth. Rather, this almost 600% increase has been achieved through large gains in National Indemnity’s traditional liability areas plus the starting of new companies (Cornhusker Casualty Company in 1970, Lakeland Fire and Casualty Company in 1971, Texas United Insurance Company in 1972, The Insurance Company of Iowa in 1973, and Kansas Fire and Casualty Company in late 1977), the purchase for cash of other insurance companies (Home and Automobile Insurance Company in 1971, Kerkling Reinsurance Corporation, now named Central Fire and Casualty Company, in 1976, and Cypress Insurance Company at yearend 1977), and finally through the marketing of additional products, most significantly reinsurance, within the National Indemnity Company corporate structure.',\n",
       "  'year': 1977},\n",
       " {'text': 'It was early in 1967 that we made our entry into this industry through the purchase of National Indemnity Company and National Fire and Marine Insurance Company (sister companies) for approximately $8.6 million. In that year their premium volume amounted to $22 million. In 1977 our aggregate insurance premium volume was $151 million. No additional shares of Berkshire Hathaway stock have been issued to achieve any of this growth. Rather, this almost 600% increase has been achieved through large gains in National Indemnity’s traditional liability areas plus the starting of new companies (Cornhusker Casualty Company in 1970, Lakeland Fire and Casualty Company in 1971, Texas United Insurance Company in 1972, The Insurance Company of Iowa in 1973, and Kansas Fire and Casualty Company in late 1977), the purchase for cash of other insurance companies (Home and Automobile Insurance Company in 1971, Kerkling Reinsurance Corporation, now named Central Fire and Casualty Company, in 1976, and Cypress Insurance Company at yearend 1977), and finally through the marketing of additional products, most significantly reinsurance, within the National Indemnity Company corporate structure. In aggregate, the insurance business has worked out very well. But it hasn’t been a one-way street. Some major mistakes have been made during the decade, both in products and personnel. We experienced significant problems from (1) a surety operation initiated in 1969, (2) the 1973 expansion of Home and Automobile’s urban auto marketing into the Miami, Florida area, (3) a still unresolved aviation “fronting” arrangement, and (4) our Worker’s Compensation operation in California, which we believe retains an interesting potential upon completion of a reorganization now in progress. It is comforting to be in a business where some mistakes can be made and yet a quite satisfactory overall performance can be achieved. In a sense, this is the opposite case from our textile business where even very good management probably can average only modest results. One of the lessons your management has learned - and, unfortunately, sometimes re-learned - is the importance of being in businesses where tailwinds prevail rather than headwinds. In 1977 the winds in insurance underwriting were squarely behind us. Very large rate increases were effected throughout the industry in 1976 to offset the disastrous underwriting results of 1974 and 1975. But, because insurance policies typically are written for one-year periods, with pricing mistakes capable of correction only upon renewal, it was 1977 before the full impact was felt upon earnings of those earlier rate increases.',\n",
       "  'year': 1977},\n",
       " {'text': 'In a sense, this is the opposite case from our textile business where even very good management probably can average only modest results. One of the lessons your management has learned - and, unfortunately, sometimes re-learned - is the importance of being in businesses where tailwinds prevail rather than headwinds. In 1977 the winds in insurance underwriting were squarely behind us. Very large rate increases were effected throughout the industry in 1976 to offset the disastrous underwriting results of 1974 and 1975. But, because insurance policies typically are written for one-year periods, with pricing mistakes capable of correction only upon renewal, it was 1977 before the full impact was felt upon earnings of those earlier rate increases. The pendulum now is beginning to swing the other way. We estimate that costs involved in the insurance areas in which we operate rise at close to 1% per month. This is due to continuous monetary inflation affecting the cost of repairing humans and property, as well as “social inflation”, a broadening definition by society and juries of what is covered by insurance policies. Unless rates rise at a comparable 1% per month, underwriting profits must shrink. Recently the pace of rate increases has slowed dramatically, and it is our expectation that underwriting margins generally will be declining by the second half of the year. We must again give credit to Phil Liesche, greatly assisted by Roland Miller in Underwriting and Bill Lyons in Claims, for an extraordinary underwriting achievement in National Indemnity’s traditional auto and general liability business during 1977. Large volume gains have been accompanied by excellent underwriting margins following contraction or withdrawal by many competitors in the wake of the 1974-75 crisis period. These conditions will reverse before long. In the meantime, National Indemnity’s underwriting profitability has increased dramatically and, in addition, large sums have been made available for investment. As markets loosen and rates become inadequate, we again will face the challenge of philosophically accepting reduced volume.',\n",
       "  'year': 1977}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load spaCy's English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define the chunk size and overlap size\n",
    "chunk_size = 15  # 15 sentences per chunk\n",
    "overlap_size = 5  # 5 sentences overlap between chunks\n",
    "\n",
    "# Function to create chunks with sliding window\n",
    "def sliding_window_chunking(text, chunk_size, overlap_size, year_metadata):\n",
    "    # Process the text with spaCy\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Create a list of sentences\n",
    "    sentences = list(doc.sents)\n",
    "    \n",
    "    # Create chunks with sliding window\n",
    "    chunks = []\n",
    "    for i in range(0, len(sentences) - chunk_size + 1, chunk_size - overlap_size):\n",
    "        chunk = sentences[i:i+chunk_size]\n",
    "        chunk_text = \" \".join([sent.text for sent in chunk])\n",
    "        chunks.append({\"text\": chunk_text, \"year\": year_metadata})\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Process the shareholder letters and create chunks for each year\n",
    "chunks_with_metadata = []\n",
    "\n",
    "for year, letter_text in shareholder_text.items():\n",
    "    # Generate chunks for each shareholder letter with year metadata\n",
    "    chunks = sliding_window_chunking(letter_text, chunk_size, overlap_size, year)\n",
    "    chunks_with_metadata.extend(chunks)\n",
    "\n",
    "# Save the chunks to a file\n",
    "with open(\"chunks_with_metadata.pkl\", \"wb\") as f:\n",
    "    pickle.dump(chunks_with_metadata, f)\n",
    "\n",
    "# Display the first 5 chunks\n",
    "chunks_with_metadata[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding Model: bge-large-en\n",
    "\n",
    "1. Large transformer architecture, more accurate than smaller models such as all-miniLM-L6-V2.\n",
    "2. High dimensional embeddings (1024-dimensional) captures rich semantic information especially for financial text.\n",
    "3. Works well with long form data such as shareholder letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SentenceTransformer model\n",
    "model = SentenceTransformer(\"BAAI/bge-large-en\")\n",
    "\n",
    "# Read the chunks with metadata\n",
    "with open(\"chunks_with_metadata.pkl\", \"rb\") as f:\n",
    "    chunks_with_metadata = pickle.load(f)\n",
    "\n",
    "# Function to generate embeddings for the text\n",
    "def generate_embeddings(data):\n",
    "    embeddings = []\n",
    "    \n",
    "    for entry in data:\n",
    "        text = entry['text']\n",
    "        year = entry['year']\n",
    "        \n",
    "        # Generate embedding for the text\n",
    "        embedding = model.encode(text)  # This returns a vector of fixed size\n",
    "        embeddings.append({'year': year, 'embedding': embedding})\n",
    "        \n",
    "    return embeddings\n",
    "\n",
    "# Generate embeddings for all the letters\n",
    "embeddings_data = generate_embeddings(chunks_with_metadata)\n",
    "\n",
    "# Optionally, save the embeddings using pickle\n",
    "with open('embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(embeddings_data, f)  # Save the embeddings with metadata (e.g., year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Embeddings on FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings loaded: 2656\n",
      "FAISS index saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the embeddings\n",
    "with open(\"embeddings.pkl\", \"rb\") as f:\n",
    "    loaded_embeddings = pickle.load(f)\n",
    "print(\"Embeddings loaded:\", len(loaded_embeddings))\n",
    "\n",
    "# Extract embeddings and metadata\n",
    "embeddings = np.array([item[\"embedding\"] for item in loaded_embeddings]).astype(\"float32\")\n",
    "years = [item[\"year\"] for item in loaded_embeddings]  # Store metadata separately\n",
    "\n",
    "# Create a FAISS index (L2 similarity)\n",
    "dimension = embeddings.shape[1]  # 1024 for BGE\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings)  # Add all embeddings to FAISS\n",
    "\n",
    "# Save FAISS index\n",
    "faiss.write_index(index, \"buffett_faiss.index\")\n",
    "print(\"FAISS index saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What are Warren Buffett's views on cryptocurrency?\n",
      "LLM Response: Based on the document chunks provided, Warren Buffett's investment strategies emphasize owning businesses that deliver goods and services efficiently and consistently over time. He values productive assets over nonproductive or currency-based assets, believing that owning first-class businesses will be the best long-term investment choice.\n",
      "\n",
      "Regarding cryptocurrency, based on the document chunks provided, there is no direct mention of Warren Buffett's views on cryptocurrency. However, his focus on tangible assets and productive businesses suggests that he may be cautious or skeptical about investing in cryptocurrency, which is a form of digital currency not backed by physical assets.\n",
      "\n",
      "Warren Buffett's investment philosophy seems to prioritize long-term value creation and sustainable growth through ownership of quality businesses. He emphasizes the importance of market economics, the rule of law, and equality of opportunity in a country's economic strength. This suggests that he would likely approach the current financial landscape by continuing to invest in businesses with strong fundamentals and a competitive advantage, rather than speculative or volatile assets like cryptocurrency.\n"
     ]
    }
   ],
   "source": [
    "# Load the SentenceTransformer model, FAISS index\n",
    "model = SentenceTransformer(\"BAAI/bge-large-en\")\n",
    "index = faiss.read_index(\"buffett_faiss.index\")\n",
    "\n",
    "# Load and extract the embeddings and chunks with metadata\n",
    "loaded_embeddings = pickle.load(open(\"embeddings.pkl\", \"rb\"))\n",
    "embeddings = np.array([item[\"embedding\"] for item in loaded_embeddings]).astype(\"float32\")\n",
    "years = [item[\"year\"] for item in loaded_embeddings]  # Store metadata separately\n",
    "\n",
    "# Load the text chunks\n",
    "chunks_with_metadata = pickle.load(open(\"chunks_with_metadata.pkl\", \"rb\"))\n",
    "sentence_chunks = [item[\"text\"] for item in chunks_with_metadata]\n",
    "\n",
    "\n",
    "\n",
    "# Function to query the FAISS index\n",
    "def query_faiss_index(query, k=5):\n",
    "    # Convert query to embedding\n",
    "    query_embedding = model.encode([query]).astype('float32')\n",
    "    \n",
    "    # Search the FAISS index for the k nearest neighbors\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    \n",
    "    # Retrieve the metadata (years) and relevant sentence chunks based on the indices\n",
    "    retrieved_metadata = [years[i] for i in indices[0]]\n",
    "    retrieved_chunks = [sentence_chunks[i] for i in indices[0]]  # Retrieve the actual document chunks\n",
    "    \n",
    "    return retrieved_metadata, retrieved_chunks, distances[0]\n",
    "\n",
    "\n",
    "\n",
    "# Function to generate the prompt dynamically for chunked sentences\n",
    "def generate_llm_prompt(retrieved_metadata, retrieved_chunks, distances, query):\n",
    "    # Start with the query\n",
    "    prompt = f\"Given the following document chunks from Berkshire Hathaway's annual letters, answer the query:\\n\\nQuery: {query}\\n\\n\"\n",
    "    \n",
    "    # Add an introductory explanation\n",
    "    prompt += \"The following document chunks are relevant to the query. Use them to answer the question based on Warren Buffett's investment strategies:\\n\\n\"\n",
    "    \n",
    "    # Process the retrieved data and add chunk sentences to the prompt with relevance scores\n",
    "    for i in range(len(retrieved_metadata)):\n",
    "        year = retrieved_metadata[i]\n",
    "        relevant_chunk = retrieved_chunks[i]  # This would be the chunk from the document\n",
    "        score = distances[i]  # The similarity score for the chunk\n",
    "        \n",
    "        prompt += f\"Year: {year} (Score: {score:.4f})\\nRelevant Document Chunk: {relevant_chunk}\\n\\n\"\n",
    "    \n",
    "    # End the prompt with the question to the LLM\n",
    "    prompt += \"Based on these document chunks, explain Warren Buffett's investment strategies and how he might approach the current financial landscape based on these past letters.\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "\n",
    "\n",
    "# Full function for querying the system\n",
    "def query_berkshire_bot(query, k=5):\n",
    "    # Step 1: Query FAISS index\n",
    "    retrieved_metadata, retrieved_chunks, distances = query_faiss_index(query, k)\n",
    "    \n",
    "    # Step 2: Craft the prompt for the LLM\n",
    "    llm_prompt = generate_llm_prompt(retrieved_metadata, retrieved_chunks, distances, query)\n",
    "    \n",
    "    # Step 3: Send the prompt to the LLM\n",
    "    client = openai.OpenAI(api_key=\"OPENAI_API_KEY\")\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": llm_prompt}]\n",
    "    )\n",
    "    response = response.model_dump()\n",
    "\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# Example usage\n",
    "query = \"What are Warren Buffett's views on cryptocurrency?\"\n",
    "response = query_berkshire_bot(query)\n",
    "print(\"Query:\", query)\n",
    "print(\"LLM Response:\", response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
